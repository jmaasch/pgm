
<div class="container">
    <p class="title is-3 has-text-centered">
        <span id="download-full">Download the full tutorial</span>
    </p> 
    <!-- 
    <p style="text-align: center;">
        This 200-page tutorial reviews the theory and methods of representation, learning, and inference in probabilistic graphical modeling.
    </p>
    -->
    <p>This 200-page tutorial reviews the theory and methods of representation, learning, and inference in probabilistic graphical modeling.</p>
    <p align="center" style="text-align: center;">
        <div class="dropdown">
            <div class="dropdown-trigger">
                <button class="button is-primary is-light" aria-haspopup="true" aria-controls="dropdown-menu">
                    <span>Download the full tutorial</span>
                    <span class="icon is-small">
                    <i class="fas fa-angle-down" aria-hidden="true"></i>
                  </span>
                </button>
            </div>
            <div class="dropdown-menu" id="dropdown-menu" role="menu">
                <div class="dropdown-content">
                    <a href="pdfs/pgm.pdf" class="dropdown-item" target="_blank" rel="noopener noreferrer">
                        Probabilistic Graphical Models: A Concise Tutorial
                    </a>
                </div>
            </div>
        </div>
        &nbsp;&nbsp;&nbsp;
        <!-- ArXiv abstract Link -->
        <span class="link-block">
            <a href="https://arxiv.org/abs/2507.17116" target="_blank"
            class="external-link button is-normal is-rounded is-primary">
            <span class="icon">
              <i class="ai ai-arxiv"></i>
            </span>
            <span>arXiv</span>
          </a>
          </span>
    </p>
</div>

***


<div class="container">
    <p class="title is-3 has-text-centered">
        <span id="download-chapters">Download tutorial chapters</span>
    </p>
<!--
    <div class="columns is-centered">
        <div class="column is-10 content has-text-centered">
            <p>Each lecture features executable Jupyter lecture notes and slides, as well as lecture videos on Youtube. We define algorithms in terms of probability and linear algebra, and we implement them in Python, Numpy and Scikit-Learn.</p>
        </div>
    </div>
 -->

    <h2>Chapter 1: Introduction.</h2>
    <p>In this brief introduction, we provide a high-level overview of what to expect from this tutorial. </p>
    <div class="columns">
        <div class="column">
            <div class="dropdown">
                <div class="dropdown-trigger">
                    <button class="button is-primary is-light" aria-haspopup="true" aria-controls="dropdown-menu">
                        <span>Download chapter</span>
                        <span class="icon is-small">
                        <i class="fas fa-angle-down" aria-hidden="true"></i>
                      </span>
                    </button>
                </div>
                <div class="dropdown-menu" id="dropdown-menu" role="menu">
                    <div class="dropdown-content">
                        <a href="pdfs/pgm_ch_1_intro.pdf" class="dropdown-item" target="_blank" rel="noopener noreferrer">
                            Chapter 1: Introduction
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

***

<div class="container">
    <h2>Chapter 2: Preliminaries.</h2>
    <div class="tags">
        <span class="tag is-link is-light">Probability</span>
        <span class="tag is-link is-light">Set theory</span>
        <span class="tag is-link is-light">Random variables</span>
        <span class="tag is-link is-light">Graph theory</span>
    </div>
    <p>This chapter covers the basics of probability theory and graph theory, which provide 
        the mathematical foundations of probablistic graphical modeling. </p>
    <div class="columns">
        <div class="column">
            <div class="dropdown">
                <div class="dropdown-trigger">
                    <button class="button is-primary is-light" aria-haspopup="true" aria-controls="dropdown-menu">
                        <span>Download chapter</span>
                        <span class="icon is-small">
                        <i class="fas fa-angle-down" aria-hidden="true"></i>
                      </span>
                    </button>
                </div>
                <div class="dropdown-menu" id="dropdown-menu" role="menu">
                    <div class="dropdown-content">
                        <a href="pdfs/pgm_ch_2_preliminaries.pdf" class="dropdown-item" target="_blank" rel="noopener noreferrer">
                            Chapter 2: Preliminaries
                        </a>
                    </div>
                </div>
            </div>
            &nbsp;&nbsp;&nbsp;
            <div class="dropdown">
                <div class="dropdown-trigger">
                    <button class="button is-info is-light" aria-haspopup="true" aria-controls="dropdown-menu">
                        <span>External resources</span>
                        <span class="icon is-small">
                        <i class="fas fa-angle-down" aria-hidden="true"></i>
                      </span>
                    </button>
                </div>
                <div class="dropdown-menu" id="dropdown-menu" role="menu">
                    <div class="dropdown-content">
                        <a href="https://www-sop.inria.fr/members/Giovanni.Neglia/probas/bertsekas_tsitsiklis_probability.pdf" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            Lecture Notes: MIT 6.041 – Introduction to Probability
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="https://www.youtube.com/playlist?list=PLUl4u3cNGP61MdtwGTqZA0MreSaDybji8" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            MIT OpenCourseWare: MIT 6.041 – Probabilistic Systems Analysis & Applied Probability
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

***

<div class="container">
    <h2>Chapter 3: Representation.</h2>
    <div class="tags">
        <span class="tag is-link is-light">Markov random fields</span>
        <span class="tag is-link is-light">Bayesian networks</span>
        <span class="tag is-link is-light">Factor graphs</span>
        <span class="tag is-link is-light">Conditional random fields</span>
    </div>
    <p>In this chapter, we focus on general techniques for 
        parameterizing probability distributions with relatively few parameters. We explore how the resulting models 
        can be elegantly described as directed and undirected graphs. </p>
    <div class="columns">
        <div class="column">
            <div class="dropdown">
                <div class="dropdown-trigger">
                    <button class="button is-primary is-light" aria-haspopup="true" aria-controls="dropdown-menu">
                        <span>Download chapter</span>
                        <span class="icon is-small">
                        <i class="fas fa-angle-down" aria-hidden="true"></i>
                      </span>
                    </button>
                </div>
                <div class="dropdown-menu" id="dropdown-menu" role="menu">
                    <div class="dropdown-content">
                        <a href="pdfs/pgm_ch_3_representation.pdf" class="dropdown-item" target="_blank" rel="noopener noreferrer">
                            Chapter 3: Representation
                        </a>
                    </div>
                </div>
            </div>
            &nbsp;&nbsp;&nbsp;
            <div class="dropdown">
                <div class="dropdown-trigger">
                    <button class="button is-info is-light" aria-haspopup="true" aria-controls="dropdown-menu">
                        <span>External resources</span>
                        <span class="icon is-small">
                        <i class="fas fa-angle-down" aria-hidden="true"></i>
                      </span>
                    </button>
                </div>
                <div class="dropdown-menu" id="dropdown-menu" role="menu">
                    <div class="dropdown-content">
                        <a href="https://arxiv.org/abs/2002.00269" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            "A Tutorial on Learning With Bayesian Networks" (Heckerman 1996)
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="https://link.springer.com/chapter/10.1007/978-1-4899-1424-8_9" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            "From Bayesian Networks to Causal Networks" (Pearl 1995)
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="https://ieeexplore.ieee.org/document/910572" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            "Factor Graphs and the Sum-Product Algorithm" (Kschischang et al. 2001)
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="https://www.statslab.cam.ac.uk/~grg/books/hammfest/3-pdc.pdf" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            "Markov Random Fields in Statistics" (Clifford 1990)
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="https://www.nowpublishers.com/article/Details/SIG-035" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            "Markov Random Fields in Image Segmentation" (Kato and Zerubia 2012)
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="https://www.nowpublishers.com/article/Details/MAL-013" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            "An Introduction to Conditional Random Fields" (Sutton and McCallum 2012)
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

***

<div class="container">
    <h2>Chapter 4: Exact Inference.</h2>
    <div class="tags">
        <span class="tag is-link is-light">Variable elimination</span>
        <span class="tag is-link is-light">Belief propagation in trees</span>
        <span class="tag is-link is-light">Junction tree algorithm</span>
        <span class="tag is-link is-light">Exact MAP inference</span>
    </div>
    <p>In this chapter, we focus on exact probabilistic 
        inference in graphical models. Though exact inference is NP-hard
        in the general case, tractable solutions can
        be obtained for certain kinds of problems. As illustrated throughout
        this chapter, the tractability of an inference problem depends heavily
        on the structure of the graph that describes the probability of interest. </p>
    <div class="columns">
        <div class="column">
            <div class="dropdown">
                <div class="dropdown-trigger">
                    <button class="button is-primary is-light" aria-haspopup="true" aria-controls="dropdown-menu">
                        <span>Download chapter</span>
                        <span class="icon is-small">
                        <i class="fas fa-angle-down" aria-hidden="true"></i>
                      </span>
                    </button>
                </div>
                <div class="dropdown-menu" id="dropdown-menu" role="menu">
                    <div class="dropdown-content">
                        <a href="pdfs/pgm_ch_4_exact_inference.pdf" class="dropdown-item" target="_blank" rel="noopener noreferrer">
                            Chapter 4: Exact Inference
                        </a>
                    </div>
                </div>
            </div>
            &nbsp;&nbsp;&nbsp;
            <div class="dropdown">
                <div class="dropdown-trigger">
                    <button class="button is-info is-light" aria-haspopup="true" aria-controls="dropdown-menu">
                        <span>External resources</span>
                        <span class="icon is-small">
                        <i class="fas fa-angle-down" aria-hidden="true"></i>
                      </span>
                    </button>
                </div>
                <div class="dropdown-menu" id="dropdown-menu" role="menu">
                    <div class="dropdown-content">
                        <a href="http://www.stat.ucla.edu/~sczhu/Courses/UCLA/Stat_232B/chapters/Belief_prop_Tutorial.pdf" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            "Understanding Belief Propagation and its Generalizations" (Yedidia et al. 2002)
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="https://dl.acm.org/doi/abs/10.5555/2074094.2074133" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            Comparison of methods for computing marginals (Lepar and Shenoy 1998)
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="https://youtu.be/_haafsCKsmY?si=DlfwbwveTLgx7x_N" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            Berkeley CS188 Lecture 15: Variable Elimination (Pieter Abbeel)
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="https://www.youtube.com/watch?v=w4sJ8SazmFo" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            Worked examples: Elimination of one variable (Pieter Abbeel)
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="https://www.youtube.com/watch?v=FDNB0A61PGE" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            Worked examples: Variable elimination (Pieter Abbeel)
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="https://ocw.mit.edu/courses/6-438-algorithms-for-inference-fall-2014/a49d895264467b7e118bf0602616cc37_MIT6_438F14_Lec14.pdf" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            MIT 6.438 Lecture 14: The Junction Tree Algorithm
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="https://ocw.mit.edu/courses/6-438-algorithms-for-inference-fall-2014/176d4c3a360b7ee4a32169f551b0722d_MIT6_438F14_rec8.pdf" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            MIT 6.438 Recitation 8: The Junction Tree Algorithm
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

***

<div class="container">
    <h2>Chapter 5: Approximate Inference.</h2>
    <div class="tags">
        <span class="tag is-link is-light">Sampling-based methods</span>
        <span class="tag is-link is-light">Variational methods</span>
        <span class="tag is-link is-light">Approximate MAP inference</span>
    </div>
    <p>This chapter introduces the two main families of approximate inference algorithms: (1) sampling
        methods, which produce answers by repeatedly generating random
        numbers from a distribution of interest, and (2) variational methods, which
        formulate inference as an optimization problem. </p>
    <div class="columns">
        <div class="column">
            <div class="dropdown">
                <div class="dropdown-trigger">
                    <button class="button is-primary is-light" aria-haspopup="true" aria-controls="dropdown-menu">
                        <span>Download chapter</span>
                        <span class="icon is-small">
                        <i class="fas fa-angle-down" aria-hidden="true"></i>
                      </span>
                    </button>
                </div>
                <div class="dropdown-menu" id="dropdown-menu" role="menu">
                    <div class="dropdown-content">
                        <a href="pdfs/pgm_ch_5_approx_inference.pdf" class="dropdown-item" target="_blank" rel="noopener noreferrer">
                            Chapter 5: Approximate Inference
                        </a>
                    </div>
                </div>
            </div>
            &nbsp;&nbsp;&nbsp;
            <div class="dropdown">
                <div class="dropdown-trigger">
                    <button class="button is-info is-light" aria-haspopup="true" aria-controls="dropdown-menu">
                        <span>External resources</span>
                        <span class="icon is-small">
                        <i class="fas fa-angle-down" aria-hidden="true"></i>
                      </span>
                    </button>
                </div>
                <div class="dropdown-menu" id="dropdown-menu" role="menu"></div>
                    <div class="dropdown-content">
                        <a href="https://www.nowpublishers.com/article/Details/MAL-001" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            "Graphical Models, Exponential Families, and Variational Inference" (Wainwright and Jordan 2008)
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="https://www.tandfonline.com/doi/pdf/10.1080/01621459.2017.1285773?casa_token=NlXqJQ7fWjEAAAAA:4QPJz7QPYI_2tBia_Hk_mJC6SE5s2bNxiZ5f_w-cLI2__mVepAkuAsJ6XHsfIOu2IItslgUTLC9XSw" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            "Variational Inference: A Review for Statisticians" (Blei et al. 2016)
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="https://www.jmlr.org/papers/volume14/hoffman13a/hoffman13a.pdf" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            "Stochastic Variational Inference" (Hoffman et al. 2013)
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="https://link.springer.com/content/pdf/10.1023/a:1007665907178.pdf" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            "An Introduction to Variational Methods for Graphical Models" (Jordan et al. 1999)
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="https://arxiv.org/abs/1301.6725" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            "Loopy Belief Propagation for Approximate Inference" (Murphy et al. 1999)
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="https://www.nowpublishers.com/article/Details/MAL-045" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            "Backward Simulation Methods for Monte Carlo Statistical Inference" (Lindsten and Schön 2013)
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="https://www.nowpublishers.com/article/Details/MAL-052" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            "Patterns of Scalable Bayesian Inference" (Angelino et al. 2016)
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="https://www.nowpublishers.com/article/Details/MAL-074" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            "Elements of Sequential Monte Carlo" (Naesseth et al. 2019)
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="https://books.google.com/books?hl=en&lr=&id=qfRsAIKZ4rIC&oi=fnd&pg=PP1&dq=Handbook+of+Markov+chain+Monte+Carlo&ots=Rex9eOZe6Q&sig=MkugdLgY18LW2rkQ7iLE7en3Eqc#v=onepage&q=Handbook%20of%20Markov%20chain%20Monte%20Carlo&f=false" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            "Handbook of Markov Chain Monte Carlo" (Brooks et al. 2011)
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

***

<div class="container">
    <h2>Chapter 6: Learning.</h2>
    <div class="tags">
        <span class="tag is-link is-light">Learning theory</span>
        <span class="tag is-link is-light">Learning in directed models</span>
        <span class="tag is-link is-light">Learning in undirected models</span>
        <span class="tag is-link is-light">Learning in latent variable models</span>
        <span class="tag is-link is-light">Bayesian learning</span>
    </div>
    <p>This chapter introduces methods for fitting predictive models on real data. We highlight two main tasks: 
        (1) structure learning, where we want to infer variable dependencies in the graphical model, and (2) 
        parameter learning, where the graph structure is known and we want to estimate the factors. </p>
    <div class="columns">
        <div class="column">
            <div class="dropdown">
                <div class="dropdown-trigger">
                    <button class="button is-primary is-light" aria-haspopup="true" aria-controls="dropdown-menu">
                        <span>Download chapter</span>
                        <span class="icon is-small">
                        <i class="fas fa-angle-down" aria-hidden="true"></i>
                      </span>
                    </button>
                </div>
                <div class="dropdown-menu" id="dropdown-menu" role="menu">
                    <div class="dropdown-content">
                        <a href="pdfs/pgm_ch_6_learning.pdf" class="dropdown-item" target="_blank" rel="noopener noreferrer">
                            Chapter 6: Learning
                        </a>
                    </div>
                </div>
            </div>
            &nbsp;&nbsp;&nbsp;
            <div class="dropdown">
                <div class="dropdown-trigger">
                    <button class="button is-info is-light" aria-haspopup="true" aria-controls="dropdown-menu">
                        <span>External resources</span>
                        <span class="icon is-small">
                        <i class="fas fa-angle-down" aria-hidden="true"></i>
                      </span>
                    </button>
                </div>
                <div class="dropdown-menu" id="dropdown-menu" role="menu">
                    <div class="dropdown-content">
                        <a href="https://mitpress.mit.edu/9780262600323/learning-in-graphical-models/" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            "Learning in Graphical Models" (Ed. Jordan 1999)
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="https://arxiv.org/abs/1302.6815" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            "Learning Bayesian Networks: The Combination of Knowledge and Statistical Data" (Heckerman et al. 2013)
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="https://proceedings.mlr.press/r0/chickering95a.html" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            "Learning Bayesian Networks: Search Methods and Experimental Results" (Chickering et al. 1995)
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="https://www.stat.cmu.edu/~brian/peem/brainstorming%20talk%20I%20gave%20in%20networkshop/PC%20algorithm/Spirtes-Glymour-Scheines%20Causation-Prediction-Search%20SPICPA-2v1.pdf" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            "Causation, Prediction, and Search" (Spirtes et al. 2000)
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="https://dl.acm.org/doi/10.1145/3527154" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            "Survey on Structure Learning and Causal Discovery" (Vowels et al. 2022)
                        </a>
                    </div>
                    <div class="dropdown-content">
                        <a href="" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            Placeholder
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

***

<div class="container">
    <h2>Chapter 7: Discussion – The Variational Autoencoder.</h2>
    <div class="tags">
        <span class="tag is-link is-light">Deep generative latent variable models</span>
        <span class="tag is-link is-light">Auto-encoding variational bayes</span>
        <span class="tag is-link is-light">The variational autoencoder</span>
    </div>
    <p>In this concluding discussion, we present a highly influential deep probabilistic
        model: the variational autoencoder (VAE). Using the VAE as a case study, we draw connections
        among ideas from throughout this tutorial and demonstrate how these
        ideas are useful in machine learning research. </p>
    <div class="columns">
        <div class="column">
            <div class="dropdown">
                <div class="dropdown-trigger">
                    <button class="button is-primary is-light" aria-haspopup="true" aria-controls="dropdown-menu">
                        <span>Download chapter</span>
                        <span class="icon is-small">
                        <i class="fas fa-angle-down" aria-hidden="true"></i>
                      </span>
                    </button>
                </div>
                <div class="dropdown-menu" id="dropdown-menu" role="menu">
                    <div class="dropdown-content">
                        <a href="pdfs/pgm_ch_7_vae.pdf" class="dropdown-item" target="_blank" rel="noopener noreferrer">
                            Chapter 7: Discussion – The Variational Autoencoder
                        </a>
                    </div>
                </div>
            </div>
            &nbsp;&nbsp;&nbsp;
            <div class="dropdown">
                <div class="dropdown-trigger">
                    <button class="button is-info is-light" aria-haspopup="true" aria-controls="dropdown-menu">
                        <span>External resources</span>
                        <span class="icon is-small">
                        <i class="fas fa-angle-down" aria-hidden="true"></i>
                      </span>
                    </button>
                </div>
                <div class="dropdown-menu" id="dropdown-menu" role="menu">
                    <div class="dropdown-content">
                        <a href="https://www.nowpublishers.com/article/Details/MAL-056" class="dropdown-item" target="_blank" rel="noopener noreferrer" >
                            "An Introduction to Variational Autoencoders" (Kingma and Welling 2019)
                        </a>
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

***

<!--BibTex citation -->
<section class="section" id="BibTeX">
    <div class="container is-max-desktop content">
    <h2 class="title" id="bibtex">How to cite this work</h2>
    Please cite our work using the following BibTeX.<br><br>
    <pre><code>
    @misc{maasch2025pgm,
        title={Probabilistic Graphical Models: A Concise Tutorial}, 
        author={Jacqueline Maasch and Willie Neiswanger and Stefano Ermon and Volodymyr Kuleshov},
        year={2025},
        eprint={2507.17116},
        archivePrefix={arXiv},
        primaryClass={cs.LG},
        url={https://arxiv.org/abs/2507.17116}, 
    }
    </code></pre>
    </div>
</section>
<!--End BibTex citation -->

<script>
    // Script for making dropdown functional.
    // Reference: https://stackoverflow.com/a/58405701
    // Get all dropdowns on the page that aren't hoverable.
    const dropdowns = document.querySelectorAll('.dropdown:not(.is-hoverable)');

    if (dropdowns.length > 0) {
        // For each dropdown, add event handler to open on click.
        dropdowns.forEach(function(el) {
            el.addEventListener('click', function(e) {
                e.stopPropagation();
                el.classList.toggle('is-active');
            });
        });

        // If user clicks outside dropdown, close it.
        document.addEventListener('click', function(e) {
            closeDropdowns();
        });
    }

    /*
     * Close dropdowns by removing `is-active` class.
     */
    function closeDropdowns() {
        dropdowns.forEach(function(el) {
            el.classList.remove('is-active');
        });
    }

    // Close dropdowns if ESC pressed
    document.addEventListener('keydown', function (event) {
        let e = event || window.event;
        if (e.key === 'Esc' || e.key === 'Escape') {
            closeDropdowns();
        }
    });
</script>