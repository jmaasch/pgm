<div class="container">
    <p class="title is-3 has-text-centered">
        <span>About this tutorial</span>
    </p>
    <div class="columns">
        <div class="column is-6">
            <!-- 
            <strong style="font-size: 30px">About this tutorial</strong>
            <br>
            <br>
            -->
            <p style="text-align:justify;" >
                Probabilistic graphical modeling is a branch of machine
                learning that uses probability distributions to describe the
                world, make predictions, and support decision-making under uncertainty. Underlying this modeling framework is an
                elegant body of theory that bridges two mathematical traditions: probability and graph theory. This framework provides
                compact yet expressive representations of joint probability distributions, yielding powerful generative models for
                probabilistic reasoning.
                <br><br>
                This tutorial provides a concise introduction to the formalisms, methods, and applications of this modeling framework. 
                After a review of basic probability and graph theory, we explore three dominant themes: 
                <ul style="PADDING-LEFT:30px;list-style-type:'&#10022;&#xFE0E;&nbsp; ';">
                    <li>The representation of multivariate distributions as graphical models.</li>
                    <li>Algorithms for learning model parameters and graphical structures from data.</li>
                    <li>Algorithms for inference, both exact and approximate.</li>
                </ul>
            </p>
            <!-- ArXiv abstract Link -->
            <span class="link-block">
                <a href="https://arxiv.org/abs/2509.03636" target="_blank"
                class="external-link button is-normal is-rounded is-dark">
                <span class="icon">
                  <i class="ai ai-arxiv"></i>
                </span>
                <span>arXiv</span>
              </a>
              </span>
            <br>
            <p>Find the full tutorial on <a href="https://arxiv.org/abs/2507.17116" target="_blank">arXiv</a> or download individual chapter PDFs below.</p>
            <br>
            <p><b>Note:</b> This tutorial is currently undergoing peer review. We welcome readers to submit <a href="https://github.com/jmaasch/pgm/issues" target="_blank">GitHub issues</a> with suggested edits, comments, or critiques. </p>
            <!-- 
            <p style="text-align:left; margin-bottom:0;">
                <summary><strong>Topics covered.</strong></summary>
                <ul style="PADDING-LEFT:30px;list-style-type:'&#10022;&#xFE0E;&nbsp; ';">
                    <li>Basics of probability and graph theory.</li>
                    <li>Representing probability distributions with directed and undirected graphs.</li>
                    <li>Exact and approximate inference.</li>
                    <li>Learning in directed, undirected, and latent variable models.</li>
                    <li>Applications in contemporary deep generative modeling.</li>
                </ul>
            </p>
            -->
        </div>
        <div class="column is-6">
            <!--
            {% include youtube.html video="vcE9WGbi4QY" %}
            -->
            <p align="center">
                <img src='img/pgm_website_figure.png' width="100%" class="center">
              </p>
        </div>
    </div>

    <div class="column is-12">
                    <hr />
    </div>
</div>